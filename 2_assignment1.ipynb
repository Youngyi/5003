{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspark.ml.regression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6a9e15a1155a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLinearRegressionModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPipelineModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pyspark.ml.regression"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression,LinearRegressionModel\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "import numpy as np\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, IntegerType\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pickle\n",
    "\n",
    "sc = SparkContext(\"local\",'app')\n",
    "spark = SparkSession.builder.appName('name').config('spark.sql.shuffle.partitions',10).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "Add one line to find the most frequent word. Output this word and its frequency.\n",
    "\n",
    "Hint: Use sortBy(), reduce(), or max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "lines = sc.textFile('../data/README.md')\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'the', 582)]\n"
     ]
    }
   ],
   "source": [
    "# answer\n",
    "sort_value = counts.sortBy(lambda x:x[1],ascending=False)\n",
    "print sort_value.take(1) #print out the most frequent word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "Modify the word count example above, so that we only count the frequencies of those words consisting of 5 or more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'limited', 2), (u'represent', 2), (u'prefix', 1), (u'Until', 1), (u'(approximate)', 1), (u'Metadata', 1)]\n"
     ]
    }
   ],
   "source": [
    "#answer\n",
    "counts_filted = counts.filter(lambda count:len(count[0])>=5)\n",
    "print counts_filted.take(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "Consider the following piece of code:\n",
    "\n",
    "What's its output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize(xrange(1, 100))\n",
    "t = 50\n",
    "B = A.filter(lambda x: x < t)\n",
    "print B.count()\n",
    "t = 10\n",
    "C = B.filter(lambda x: x > t)  # it would generate the C and B from A once again, at this moment, t =10\n",
    "print C.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "The intent of the code above is to get all numbers below 50 from A and put them into B, and then get all numbers above 10 from B and put them into C.  Fix the code so that it produces the desired behavior, by adding one line of code.  You are not allowed to change the existing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "A = sc.parallelize(xrange(1, 100))\n",
    "t = 50\n",
    "B = A.filter(lambda x: x < t)\n",
    "B.cache()  # answer lines,. B was persisted in disk.\n",
    "t = 10\n",
    "C = B.filter(lambda x: x > t)\n",
    "print C.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "Modify the PMI example by sending a_dict and n_dict inside the closure. Do not use broadcast variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = sc.textFile('../data/adj_noun_pairs.txt')\n",
    "\n",
    "pairs = lines.map(lambda l: tuple(l.split())).filter(lambda p: len(p)==2)\n",
    "pairs.cache()\n",
    "\n",
    "N=pairs.count()\n",
    "\n",
    "pair_freqs = pairs.map(lambda p: (p,1)).reduceByKey(lambda f1, f2: f1 + f2) \\\n",
    "                  .filter(lambda pf: pf[1] >= 1)\n",
    "\n",
    "# Computing the frequencies of the adjectives and the nouns\n",
    "a_freqs = pairs.map(lambda p: (p[0],1)).reduceByKey(lambda x,y: x+y)\n",
    "n_freqs = pairs.map(lambda p: (p[1],1)).reduceByKey(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# answer\n",
    "n_dict = n_freqs.collectAsMap()  #change\n",
    "a_dict =a_freqs.collectAsMap()  #change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21.59271342368657, (u'\\u9ad8\\u91ce\\u8c46\\u8150', u'k\\u014dyad\\u014dfu')),\n",
       " (21.59271342368657, (u'\\u997f', u'\\xe8')),\n",
       " (21.59271342368657, (u'\\u9648\\u8bda', u'\\u9673\\u8aa0')),\n",
       " (21.59271342368657, (u'\\u9648\\u6bc5', u'\\u9673\\u6bc5')),\n",
       " (21.59271342368657, (u'\\u8a00\\u8449engrish', u'\\u3002')),\n",
       " (21.59271342368657, (u'\\u7d2f', u'l\\xe8i')),\n",
       " (21.59271342368657, (u'\\u7b28', u'b\\xe8n')),\n",
       " (21.59271342368657, (u'\\u6ce2\\u52d5\\u62f3', u'Hadouken')),\n",
       " (21.59271342368657, (u'\\u6cc9\\u6f33\\u90fd\\u6307\\u63ee\\u4f7f', u'xiao4')),\n",
       " (21.59271342368657, (u'\\u5f8c\\u9ad8\\u5009\\u9662', u'Go-Takakura-in'))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import *\n",
    "# Computing the PMI for a pair.\n",
    "# Computing the PMI for a pair.\n",
    "def pmi_score(pair_freq):\n",
    "    global a_dict,n_dict\n",
    "    w1, w2 = pair_freq[0]\n",
    "    f = pair_freq[1]\n",
    "    pmi = log(float(f)*N/(a_dict[w1]*n_dict[w2]), 2)  #change\n",
    "    return pmi, (w1, w2)\n",
    "\n",
    "# Computing the PMI for all pairs.\n",
    "scored_pairs = pair_freqs.map(pmi_score)\n",
    "# Printing the most strongly associated pairs. \n",
    "scored_pairs.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair_freqs = pairs.map(lambda p: (p,1)).reduceByKey(lambda f1, f2: f1 + f2)\n",
    "print pair_freqs.sortBy(lambda x:x[1],ascending=False).map(lambda x:x[0]).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
